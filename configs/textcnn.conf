[global]
# 模型类型
model_type = TextCNN
test_split = 0.2

[data]
# 自定义词典
# user_dict_path = data/comment_userdict.txt.gz
user_dict_path =

# 原始语料：标签与句子用空格分隔开
# 标签格式: 三分类-(1,2,3)
corpus_path = data/textcnn/corpus.txt

# 分割后语料:用空格分割开的词组,第一个为标签
# 标签格式:三分类-(__label__1, __label__2, __label__3)
# __label__2 , birchas chaim , yeshiva birchas chaim is a orthodox
seg_corpus_path = data/textcnn/corpus_seg.txt

# 增加语料预采样的地址
sample_corpus_path = data/textcnn/corpus_sample.txt

# 是否进行预采样
sample = False

# 词典地址
vocabs_path = data/textcnn/vocabs.txt

# 模型地址
model_path = outputs/model/textcnn/model.ckpt

# 词向量模型地址
embedding_model_path = outputs/model/textcnn/embedding_model.ckpt

# 训练集地址
train_dataset_path = data/textcnn/train.npz

# 测试集地址
test_dataset_path = data/textcnn/test.npz



[model]
pre_embedding = True
load_pretrained = False
epoch = 1
num_classes = 2
sequence_length = 40
embedding_size = 200
filter_sizes = [2, 3, 5]
num_filters = 32
batch_size = 32
learning_rate = 0.001
dropout = 0.5
l2_reg_lambda = 0.0
embedding_initializer = 'uniform'
kernel_initializer = 'he_uniform'


[word_embedding]
model = "skipgram"
lr = 0.05
dim = 200
ws = 5
epoch = 10
minCount = 5
minCountLabel = 0
minn = 3
maxn = 6
neg = 5
wordNgrams = 1
loss = "ns"
bucket = 2000000
thread = 12
lrUpdateRate = 100
t = 1e-4
label = "__label__"
verbose = 2
pretrainedVectors = ""
